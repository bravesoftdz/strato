# Rough patch

I've been struggling a while now. Every time I decide to look at it again, even if I try from a different angle, it feels like I get stuck not finding a good plan to go forward. It's a bit of work to explain what it's about, but hang on. It'll show you what things I'm considering all at once, just to get the design good right from the start.

So, I made a lexer/tokenizer, I started a parser that would go over the output and fill a series of nodes into a tree. Since all the data is already there, I started using the tree to resolve look-ups rightaway. Since it's right there in memory, I was vaguely hoping it would serve some advantage with caching somehow, bit when work progresses I guess there may be a time when I could do more benchmarking and prove or disprove some or all of this.

To get things to work (on the first few Euler project tasks, you got to have it do something...) I started a really limited run-time, and interpreter that walks this AST. And for a while it was a roughly decent milestone and stepstone for further work. But also a dangerous state to leave an attempt at a compiler in. *Loose* languages, both strongly and dynamically typed, that first existed in somewhat mature form primarily interpreted, suffered from a conflict of interest where the interpreter doing its job behind the scene would get called upon for some of the language features.

Then, when studying a bit more existing compilers first, I found out I wasn't planning in a linking step. When parsing, all look-ups would take place right there and then, and not in a separate linking step. Apparently compilers typically list a set of *externals* for each *module* (nomenclature may vary) and the linking step then attempts to resolve all of those at once, in a kind of blunt force operation. I understand this is where unused code is eliminated, but I also understand this is where the dependency tree is at the forefront. In a way it looks to me the linker step has to re-construct it once again, though it's already right there in the AST. At least, I feel it should be.

So, up to me to make it happen. And this is where I find this inversion I need to tackle. Let's say you have a tree of source-files that *import* eachother. Typically a *project* has a main file that imports a few files that define the main elements of the program, holding code in there that would serve as entry point. To make anything work you'll (eventually) need to talk to the system with one or more layers inbetween, so by importing platforms, frameworks and the effective system API (wrapper), you'll typically get a sizable tree where each child has gotten imported by it's parent.

This is not what you need. A running program needs somewhat of the opposite of this. At the root would be the system's API (wrapper), then the tools and libraries that build upon this, and finally the code specific to the project. It's this tree I would like to build into my current AST, and serve as a *guide* to a partial re-compile when only a single source-file gets changed. Then to catch any changes made, all files that depend on that file somehow, should get re-processed as well.

To save on calls to the memory manager, I was allocating blocks of nodes at a time to build into the AST, so I thought to 'drop' entire blocks from the tree and re-use the memory when parsing the updated file(s), and using the dependency tree, any blocks/files that were dependent on this block/file. But the dependency data is stored in this same node data as well, so there's possibly a delicate moment when the block is about to get dropped, but the dependency data is still in use...

But I guess I'll just roll ahead and find an elegant solution to the problem when I really get that far.
